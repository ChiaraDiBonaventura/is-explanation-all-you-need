# is-explanation-all-you-need
Data repository for the paper **"Is Explanation All You Need? An Expert Survey on LLM-generated Explanations for Abusive Language Detection"** to be published in the Proceedings of the 10th Italian Conference in Computational Linguistics (CLiC-it 2024). 

The .csv file in the data folder contains the full set of explanations generated by different language models with different learning strategies. Participants were shown a sample of these explanations. 

The data columns are: 
* *dataset ID*: HX or IH depending on whether the text was sampled from HateXplain or Implicit Hate corpus, respectively; 
* *text ID*: the id of the text as shown in the dataset;
* *text*: pre-processed version of the original text in the dataset;
* *class*: label of the text as shown in the original dataset; 
* *groundtruth explanation*: structured version of the original explanation for the text in the dataset;
* *alpaca_zsl*: explanations generated by FLAN-ALPACA model when prompted with zero-shot learning;
* *alpaca_fsl*: explanations generated by FLAN-ALPACA model when prompted with few-shot learning;
* *alpaca_kg*: explanations generated by FLAN-ALPACA model when prompted with knowledge-guided learning;
* *flan_t5_zsl*: explanations generated by FLAN-T5 model when prompted with zero-shot learning;
* *flan_t5_fsl*: explanations generated by FLAN-T5 model when prompted with few-shot learning;
* *flan_t5_kg*: explanations generated by FLAN-T5 model when prompted with knowledge-guided learning;
* *mt0_zsl*: explanations generated by mT0 model when prompted with zero-shot learning;
* *mt0_fsl*: explanations generated by mT0 model when prompted with few-shot learning;
* *mt0_kg*: explanations generated by mT0 model when prompted with knowledge-guided learning;
* *llama_zsl*: explanations generated by Llama 2 model when prompted with zero-shot learning;
* *llama_ft*: explanations generated by Llama 2 model when instruction finetuned with vanilla prompts;
* *llama_kg_ft*: explanations generated by Llama 2 model when instruction finetuned with knowledge-guided prompts. 
